{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":377107,"sourceType":"datasetVersion","datasetId":165566}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50, VGG16\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Model\nfrom keras import layers\nfrom keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nimport matplotlib.pyplot as plt\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.callbacks import EarlyStopping\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-11T16:33:50.305523Z","iopub.execute_input":"2024-08-11T16:33:50.305954Z","iopub.status.idle":"2024-08-11T16:33:50.314257Z","shell.execute_reply.started":"2024-08-11T16:33:50.305921Z","shell.execute_reply":"2024-08-11T16:33:50.312891Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"img_with_tumor_dir = '/kaggle/input/brain-mri-images-for-brain-tumor-detection/yes'\nimg_without_tumor_dir = '/kaggle/input/brain-mri-images-for-brain-tumor-detection/no'","metadata":{"execution":{"iopub.status.busy":"2024-08-11T17:48:56.217543Z","iopub.execute_input":"2024-08-11T17:48:56.217967Z","iopub.status.idle":"2024-08-11T17:48:56.223591Z","shell.execute_reply.started":"2024-08-11T17:48:56.217936Z","shell.execute_reply":"2024-08-11T17:48:56.222349Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"print('There are {} images with tumor'.format(len(img_with_tumor_dir)))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T17:50:08.844386Z","iopub.execute_input":"2024-08-11T17:50:08.845393Z","iopub.status.idle":"2024-08-11T17:50:08.850463Z","shell.execute_reply.started":"2024-08-11T17:50:08.845357Z","shell.execute_reply":"2024-08-11T17:50:08.849359Z"},"trusted":true},"execution_count":170,"outputs":[{"name":"stdout","text":"There are 60 images with tumor\n","output_type":"stream"}]},{"cell_type":"code","source":"print('There are {} images without tumor'.format(len(img_without_tumor_dir)))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T17:50:12.401902Z","iopub.execute_input":"2024-08-11T17:50:12.402850Z","iopub.status.idle":"2024-08-11T17:50:12.407830Z","shell.execute_reply.started":"2024-08-11T17:50:12.402812Z","shell.execute_reply":"2024-08-11T17:50:12.406727Z"},"trusted":true},"execution_count":171,"outputs":[{"name":"stdout","text":"There are 59 images without tumor\n","output_type":"stream"}]},{"cell_type":"code","source":"img_height, img_width = 224, 224\nbatch_size = 16\nepochs = 30\nlearning_rate = 0.0001\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:15:48.444611Z","iopub.execute_input":"2024-08-11T18:15:48.445050Z","iopub.status.idle":"2024-08-11T18:15:48.450601Z","shell.execute_reply.started":"2024-08-11T18:15:48.445011Z","shell.execute_reply":"2024-08-11T18:15:48.449533Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"# Image data generator with rescaling\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\n# Training data generator\ntrain_generator = datagen.flow_from_directory(\n    dataset_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training',\n    shuffle=True\n)\n\n# Validation data generator\nvalidation_generator = datagen.flow_from_directory(\n    dataset_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation',\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:02:33.136933Z","iopub.execute_input":"2024-08-11T18:02:33.137331Z","iopub.status.idle":"2024-08-11T18:02:33.172680Z","shell.execute_reply.started":"2024-08-11T18:02:33.137299Z","shell.execute_reply":"2024-08-11T18:02:33.171615Z"},"trusted":true},"execution_count":192,"outputs":[{"name":"stdout","text":"Found 406 images belonging to 3 classes.\nFound 100 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# load base model\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:02:36.936406Z","iopub.execute_input":"2024-08-11T18:02:36.936830Z","iopub.status.idle":"2024-08-11T18:02:37.256991Z","shell.execute_reply.started":"2024-08-11T18:02:36.936789Z","shell.execute_reply":"2024-08-11T18:02:37.255895Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"# Freeze the layers which you don't want to train\nfor layer in base_model.layers[-10:]:\n    layer.trainable = False\n\n\n# Create a new model\nmodel = Sequential()\n\n# Add the VGG16 base model\nmodel.add(base_model)\n\n# Add new custom layers\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:16:16.483640Z","iopub.execute_input":"2024-08-11T18:16:16.484697Z","iopub.status.idle":"2024-08-11T18:16:16.500371Z","shell.execute_reply.started":"2024-08-11T18:16:16.484650Z","shell.execute_reply":"2024-08-11T18:16:16.498772Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"# Option 1: Use RMSprop\noptimizer_1 = RMSprop(learning_rate=learning_rate)\n\n# Option 2: Use SGD with momentum\noptimizer_2 = SGD(learning_rate=learning_rate, momentum=0.9)\n\n# Option 3: Use Adam \noptimizer_3 = Adam(learning_rate=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:10:48.534210Z","iopub.execute_input":"2024-08-11T18:10:48.534596Z","iopub.status.idle":"2024-08-11T18:10:48.549932Z","shell.execute_reply.started":"2024-08-11T18:10:48.534567Z","shell.execute_reply":"2024-08-11T18:10:48.548727Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=optimizer_3, \n              loss='binary_crossentropy', \n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:16:36.954633Z","iopub.execute_input":"2024-08-11T18:16:36.955094Z","iopub.status.idle":"2024-08-11T18:16:36.983724Z","shell.execute_reply.started":"2024-08-11T18:16:36.955061Z","shell.execute_reply":"2024-08-11T18:16:36.982573Z"},"trusted":true},"execution_count":213,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_26\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_40 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m12,845,568\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_72 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,568</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m53,252,933\u001b[0m (203.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,252,933</span> (203.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,846,081\u001b[0m (49.00 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,846,081</span> (49.00 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m25,692,164\u001b[0m (98.01 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,692,164</span> (98.01 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n#class_weight = {0: 1., 1: 1.5}  \n\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=epochs,\n    #class_weight=class_weight,\n    callbacks=[early_stopping, reduce_lr]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:16:39.164514Z","iopub.execute_input":"2024-08-11T18:16:39.165253Z","iopub.status.idle":"2024-08-11T18:16:39.761348Z","shell.execute_reply.started":"2024-08-11T18:16:39.165217Z","shell.execute_reply":"2024-08-11T18:16:39.759778Z"},"trusted":true},"execution_count":214,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[214], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#class_weight = {0: 1., 1: 1.5}  \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#class_weight=class_weight,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:228\u001b[0m, in \u001b[0;36mBaseOptimizer._check_variables_are_known\u001b[0;34m(self, variables)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(v) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables_indices:\n\u001b[0;32m--> 228\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This optimizer can only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe called for the variables it was originally built with. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen working with a new set of variables, you should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecreate a new optimizer instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: Unknown variable: <KerasVariable shape=(25088, 512), dtype=float32, path=sequential_26/dense_71/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance."],"ename":"ValueError","evalue":"Unknown variable: <KerasVariable shape=(25088, 512), dtype=float32, path=sequential_26/dense_71/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\nprint(f\"Validation Loss: {loss}\")\nprint(f\"Validation Accuracy: {accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation accuracy and loss values\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example function to predict tumor presence\ndef predict_tumor(img_path):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array /= 255.0\n\n    prediction = model.predict(img_array)\n    if prediction[0] > 0.5:\n        print(\"Tumor detected.\")\n    else:\n        print(\"No tumor detected.\")","metadata":{},"execution_count":null,"outputs":[]}]}